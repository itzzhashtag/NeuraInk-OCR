{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a777b8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hashtag\\AppData\\Local\\Temp\\ipykernel_4504\\3433335856.py:39: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(include_top=False, weights='imagenet', input_tensor=input_layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting Stage 1 training...\n",
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.4755 - loss: 2.1287"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 238ms/step - accuracy: 0.4756 - loss: 2.1278 - val_accuracy: 0.6922 - val_loss: 1.0370 - learning_rate: 0.0010\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6874 - loss: 1.0837"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 253ms/step - accuracy: 0.6874 - loss: 1.0836 - val_accuracy: 0.7340 - val_loss: 0.8869 - learning_rate: 0.0010\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7132 - loss: 0.9575"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 235ms/step - accuracy: 0.7132 - loss: 0.9575 - val_accuracy: 0.7423 - val_loss: 0.8565 - learning_rate: 0.0010\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7294 - loss: 0.8941"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 252ms/step - accuracy: 0.7294 - loss: 0.8941 - val_accuracy: 0.7455 - val_loss: 0.8402 - learning_rate: 0.0010\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 244ms/step - accuracy: 0.7399 - loss: 0.8654 - val_accuracy: 0.7461 - val_loss: 0.8439 - learning_rate: 0.0010\n",
      "[INFO] Starting Stage 2 fine-tuning...\n",
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 293ms/step - accuracy: 0.3031 - loss: 3.0502 - val_accuracy: 0.6630 - val_loss: 1.1642 - learning_rate: 1.0000e-05\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 297ms/step - accuracy: 0.5482 - loss: 1.6563 - val_accuracy: 0.6737 - val_loss: 1.1333 - learning_rate: 1.0000e-05\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 305ms/step - accuracy: 0.6262 - loss: 1.3194 - val_accuracy: 0.7055 - val_loss: 1.0096 - learning_rate: 1.0000e-05\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 296ms/step - accuracy: 0.6704 - loss: 1.1415 - val_accuracy: 0.7286 - val_loss: 0.9151 - learning_rate: 1.0000e-05\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 296ms/step - accuracy: 0.7012 - loss: 1.0232 - val_accuracy: 0.7455 - val_loss: 0.8486 - learning_rate: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model and history saved.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Config\n",
    "IMG_SIZE = 64\n",
    "NUM_CLASSES = 62\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS_INITIAL = 5\n",
    "EPOCHS_FINE_TUNE = 5\n",
    "\n",
    "# Disable mixed precision (too heavy for your CPU)\n",
    "# tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess(image, label):\n",
    "    image = tf.image.transpose(image)  # match EMNIST orientation\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.image.grayscale_to_rgb(image)\n",
    "    label = tf.one_hot(label, NUM_CLASSES)\n",
    "    return image, label\n",
    "\n",
    "# Load and prepare EMNIST\n",
    "(ds_train, ds_test), ds_info = tfds.load('emnist/byclass', split=['train', 'test'], as_supervised=True, with_info=True)\n",
    "ds_train = ds_train.take(40000)  # speed up\n",
    "\n",
    "train_ds = ds_train.map(preprocess).shuffle(2048).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = ds_test.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# MobileNetV2 model\n",
    "input_layer = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "base_model = MobileNetV2(include_top=False, weights='imagenet', input_tensor=input_layer)\n",
    "base_model.trainable = False\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "x = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "output = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = models.Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer=Adam(1e-3),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=3, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(patience=2, factor=0.5, min_lr=1e-6),\n",
    "    ModelCheckpoint(\"EMNIST_MobileNetV2_best.h5\", save_best_only=True)\n",
    "]\n",
    "\n",
    "print(\"[INFO] Starting Stage 1 training...\")\n",
    "model.fit(train_ds, validation_data=test_ds, epochs=EPOCHS_INITIAL, callbacks=callbacks)\n",
    "\n",
    "# Fine-tuning\n",
    "for layer in base_model.layers[-20:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=Adam(1e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"[INFO] Starting Stage 2 fine-tuning...\")\n",
    "history = model.fit(train_ds, validation_data=test_ds, epochs=EPOCHS_FINE_TUNE, callbacks=callbacks)\n",
    "\n",
    "# Save\n",
    "model.save(\"mobilenet_emnist_gui_model.h5\")\n",
    "with open('emnist_mobilenet_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "print(\"✅ Model and history saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429c4fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
